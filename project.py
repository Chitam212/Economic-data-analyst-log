# -*- coding: utf-8 -*-
"""ĐATN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KNcqh09baFIYFJ0-2yZNXbDZLTWkdL4-
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data= pd.read_csv('/content/drive/MyDrive/DATN/Dataraw.csv', encoding='latin1')

data.info()

data["Late_delivery_risk"].value_counts(normalize = True)*100

"""# **1. Exploratory Data Analysis**

"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings("ignore")

"""## **1.1 Data Visualization**

**SALES PER DELIVERY STATUS:**
"""

sales_per_delivery_status = data.groupby('Delivery Status')['Sales'].sum()
sales_per_delivery_status

"""Late delivery chiếm phần lớn doanh thu → có thể là do khách hàng lớn, hoặc do sản phẩm đắt tiền thường gặp trễ.

Canceled shipping thấp → ít bị hủy, tốt cho vận hành.
"""

plt.figure(figsize=(6,5))
colors = ['#60A5FA', '#1D2951', '#003153', '#000080']

def fmt(pct, vals):
    v = int(pct/100.*sum(vals))
    return f'{pct:.1f}%\n(${v/1e6:.1f}M)' if pct > 5 else ''

plt.pie(
    sales_per_delivery_status,
    labels=sales_per_delivery_status.index,
    autopct=lambda p: fmt(p, sales_per_delivery_status),
    colors=colors,
    startangle=90,
    textprops={'fontsize':9, 'color':'white'},
    wedgeprops={'edgecolor':'white','linewidth':1.2}
)

plt.title('Sales by Delivery Status', color='#000080', fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()

"""Biểu đồ tròn này cho thấy cơ cấu doanh thu theo trạng thái giao hàng.
Phần lớn doanh thu (54,7%) đến từ các đơn hàng giao trễ, cho thấy một vấn đề vận hành nghiêm trọng có thể ảnh hưởng đến mức độ hài lòng của khách hàng.
Các đơn hàng giao sớm chiếm 23,2% doanh thu, thể hiện một phần hiệu quả trong quy trình vận hành, trong khi các đơn giao đúng hạn chiếm 17,9%.
Các đơn bị hủy chiếm 4,3% doanh thu, gợi ý một khoản thất thoát doanh thu tiềm tàng.
Việc doanh thu chủ yếu đến từ các đơn giao trễ cho thấy rằng cải thiện thời gian giao hàng có thể nâng cao sự hài lòng khách hàng và giảm rủi ro vận hành.

**SALES PER MARKET**
"""

sales_per_market = data.groupby('Market')['Sales'].sum().sort_values(ascending=False)

plt.figure(figsize=(8,5.2))
colors = ['#000080', '#1D2951', '#6A5ACD', '#9CA3AF', '#7B68EE', '#4B0082']

ax = sns.barplot(
    x=sales_per_market.index,
    y=sales_per_market.values,
    palette=colors[:len(sales_per_market)],
    edgecolor='white'
)

for i, v in enumerate(sales_per_market.values):
    ax.text(i, v, f'{v/1e6:.1f}M', ha='center', va='bottom', fontsize=9, color='#1D2951')

plt.title('Sales by Market', color='#000080', fontsize=13, fontweight='bold', pad=10)
plt.xlabel('Market', fontsize=11, color='#1D2951', labelpad=5)
plt.ylabel('Sales', fontsize=11, color='#1D2951')
plt.xticks(rotation=45, fontsize=10, color='#1D2951')
plt.yticks(color='#1D2951')
sns.despine()
plt.tight_layout()
plt.show()

"""Châu Âu dẫn đầu về doanh thu, đóng góp lớn nhất, theo sát là khu vực LATAM.
Khu vực Thái Bình Dương – Châu Á cũng chiếm một phần đáng kể trong tổng doanh thu nhưng vẫn thấp hơn Châu Âu và LATAM.
Khu vực USCA đứng sau đó, trong khi Châu Phi có mức doanh thu thấp nhất trong các thị trường.
Khoảng cách rõ rệt giữa các khu vực này cho thấy sự khác biệt tiềm tàng về quy mô thị trường, tệp khách hàng hoặc hiệu suất giao hàng giữa các vùng địa lý.

**TOP 10 SALES PER PRODUCT CATEGORY:**
"""

sales_per_category = data.groupby('Category Name')['Sales'].sum().sort_values(ascending=False)
top_10 = sales_per_category.head(10)

sns.set_style("white")

plt.figure(figsize=(8, 5))

colors = ['#000080', '#1D2951', '#4B0082', '#6A5ACD', '#7B68EE',
          '#9CA3AF', '#8A7CA8', '#C1A7E4', '#D8C6F0', '#EDE6FA']

bars = sns.barplot(
    x=top_10.index,
    y=top_10.values,
    palette=colors[:len(top_10)],
    saturation=0.9
)
for i, v in enumerate(top_10.values):
    plt.text(i, v + (v * 0.06), f'{v:,.0f}', ha='center', va='bottom', fontsize=9.5, color='#1D2951')
plt.title('Top 10 Sales per Product Category', fontsize=13, weight='bold', color='#000080')
plt.xlabel('')
plt.ylabel('')
plt.xticks(rotation=35, ha='right', fontsize=10, color='#1D2951')
plt.yticks([], color='#1D2951')

sns.despine(left=True, bottom=True)

plt.tight_layout()
plt.show()

"""**TOP 10 REGIONS WITH LOSS:**

Biểu đồ cột này thể hiện 10 danh mục sản phẩm có doanh số cao nhất.
Danh mục Fishing dẫn đầu rõ rệt với doanh số hơn 6 triệu USD, theo sau là Cleats và Camping & Hiking, mỗi danh mục đóng góp khoảng 4 triệu USD.
Các nhóm như Cardio Equipment, Women's Apparel, và Water Sports có doanh số thấp hơn một chút nhưng vẫn ở mức đáng kể.
Ngoài ra, Men’s Footwear, Indoor/Outdoor Games, và Shop By Sport cũng đạt kết quả tốt, trong khi Computers đứng cuối trong top 10 danh mục có doanh số cao nhất.
"""

regions_with_loss = data[data['Benefit per order'] < 0].groupby('Order Region')['Sales'].sum().sort_values(ascending=False)
regions_with_loss.head(10)

top_10_loss = regions_with_loss.head(10)

plt.figure(figsize=(8, 5))
colors = ['#000080', '#1D2951', '#4B0082', '#6A5ACD', '#7B68EE', '#9CA3AF', '#5F6F94', '#8791B2', '#A0A5C8', '#C5CAE9']

ax = sns.barplot(
    x=top_10_loss.values,
    y=top_10_loss.index,
    palette=colors[:len(top_10_loss)]
)

# Hiển thị số cuối mỗi cột
for i, v in enumerate(top_10_loss.values):
    ax.text(v + abs(v)*0.02, i, f"{v:,.0f}", va='center', fontsize=9, color='#1D2951')

plt.title('Top 10 Regions with Loss (Benefit < 0)', fontsize=13, color='#000080', fontweight='bold')
plt.xlabel('Total Loss (USD)', fontsize=11, color='#1D2951')
plt.ylabel('Region', fontsize=11, color='#1D2951')
plt.xticks(color='#1D2951')
plt.yticks(color='#1D2951')
sns.despine(left=True, bottom=True)
plt.tight_layout()
plt.show()

"""Tây Âu có mức thua lỗ lớn nhất, với Trung Mỹ và Nam Mỹ xếp ngay sau. Mặc dù Bắc Âu, Châu Đại Dương và Nam Âu cũng ghi nhận sụt giảm đáng kể, nhưng mức độ nhẹ hơn. Các khu vực như Đông Nam Á, Caribe, Nam Á và miền Tây Hoa Kỳ có mức thua lỗ nhỏ hơn, cho thấy sự ổn định tương đối nhưng vẫn cần theo dõi. Việc tập trung vào các khu vực có mức thua lỗ cao có thể giúp xác định điểm yếu trong vận hành và cải thiện lợi nhuận.

**TOP 10 PRODUCTS WITH LOSS:**
"""

top_10_products_loss = (
    data[data['Benefit per order'] < 0]
    .groupby('Product Name')['Sales']
    .sum()
    .sort_values(ascending=False)
    .head(10)
)

plt.figure(figsize=(8, 5))
colors = ['#000080', '#1D2951', '#4B0082', '#6A5ACD', '#7B68EE', '#9CA3AF', '#5F6F94', '#8791B2', '#A0A5C8', '#C5CAE9']

ax = sns.barplot(
    x=top_10_products_loss.values,
    y=top_10_products_loss.index,
    palette=colors[:len(top_10_products_loss)]
)

# Hiển thị số cuối mỗi thanh
for i, v in enumerate(top_10_products_loss.values):
    ax.text(v + abs(v)*0.015, i, f"{v:,.0f}", va='center', fontsize=9, color='#1D2951')

plt.title('Top 10 Products with Loss (Benefit < 0)', fontsize=13, color='#000080', fontweight='bold')
plt.xlabel('Total Loss (USD)', fontsize=11, color='#1D2951')
plt.ylabel('Product', fontsize=11, color='#1D2951')
plt.xticks(color='#1D2951')
plt.yticks(color='#1D2951')
sns.despine(left=True, bottom=True)
plt.tight_layout()
plt.show()

"""**PAYMENT TYPE VS. LATE DELIVERY RISK:**"""

payment_late_risk = data.groupby(['Type', 'Late_delivery_risk']).size().reset_index(name='Count')

plt.figure(figsize=(8, 4))
sns.barplot(
    data=payment_late_risk,
    x='Type',
    y='Count',
    hue='Late_delivery_risk',
    palette=['#001F3F', '#0074D9']
)

plt.xlabel('')
plt.ylabel('')
plt.title('')
plt.xticks(rotation=0, fontsize=11)
plt.yticks(fontsize=10)

plt.tight_layout()
plt.show()

"""Phân tích: Hình thức thanh toán và rủi ro giao hàng trễ

Biểu đồ cột này mô tả **mối quan hệ giữa các hình thức thanh toán khác nhau và rủi ro giao hàng trễ**.  
- **DEBIT** có số lượng đơn hàng giao trễ cao nhất (màu cam), vượt trội so với đơn hàng giao đúng hạn.  
- **CASH** có tổng số đơn hàng thấp nhất, với số đơn giao trễ cũng ít hơn so với các hình thức khác.  
- **PAYMENT** và **TRANSFER** có tỷ lệ đơn giao đúng hạn (màu xanh) và giao trễ tương đối cân bằng.  

 Kết quả cho thấy một số hình thức thanh toán, đặc biệt là **DEBIT**, có liên quan đến **rủi ro giao hàng trễ cao hơn**, gợi ý khả năng tồn tại **bất cập trong quy trình vận hành hoặc xử lý giao dịch** đối với các loại thanh toán này.

**NUMBER OF ORDERS FROM DIFFERENT DEPARTMENTS VS SHIPPING MODE:**
"""

category_shipping = data.groupby(['Department Name', 'Shipping Mode']).size().unstack(fill_value=0)

colors = ['#1D2951', '#7B68EE', '#87CEFA', '#90EE90']

plt.figure(figsize=(8, 5))
sns.set_style("whitegrid")

for mode, color in zip(category_shipping.columns, colors):
    plt.plot(
        category_shipping.index,
        category_shipping[mode],
        marker='o',
        linewidth=2.5,
        markersize=6,
        label=mode,
        color=color
    )

# Làm sạch và tinh chỉnh
plt.xticks(rotation=30, ha='right', fontsize=10, color='#1D2951')
plt.yticks(fontsize=10, color='#1D2951')
plt.title('Orders by Department and Shipping Mode', fontsize=13, fontweight='bold', color='#1D2951')
plt.grid(alpha=0.2)
plt.legend(frameon=False, loc='upper right')
sns.despine(left=True, bottom=True)

plt.tight_layout()
plt.show()

"""**LATE DELIVERIES VS. SHIPPING MODE VS. REGION:**"""

plt.figure(figsize=(12, 8))
sns.scatterplot(
    data=data,
    x='Order Region',
    y='Shipping Mode',
    hue='Late_delivery_risk',
    size='Sales',
    sizes=(50, 500),
    palette={0: '#1f77b4', 1: '#ff7f0e'},  # xanh dương & cam
    alpha=0.7
)

plt.title('Mối quan hệ giữa Trễ giao hàng - Hình thức giao hàng - Khu vực', fontsize=14, weight='bold')
plt.xlabel('Khu vực đặt hàng', fontsize=12)
plt.ylabel('Hình thức giao hàng', fontsize=12)
plt.xticks(rotation=45, fontsize=10, ha='right')

# Cập nhật chú thích tiếng Việt
handles, labels = plt.gca().get_legend_handles_labels()
new_labels = ['Giao đúng hạn' if l == '0' else 'Giao trễ' if l == '1' else l for l in labels]
plt.legend(handles, new_labels, title='Tình trạng giao hàng', fontsize=10, title_fontsize=11)

plt.tight_layout(pad=2)
plt.show()

"""**DELIVERY STATUS BY SHIPPING MODE:**"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Tạo crosstab để tính tỷ lệ phần trăm
delivery_status_count = pd.crosstab(
    data['Shipping Mode'],
    data['Delivery Status']
)

# Chuyển sang tỷ lệ phần trăm
delivery_status_percent = delivery_status_count.div(
    delivery_status_count.sum(axis=1),
    axis=0
) * 100

# Vẽ biểu đồ
plt.figure(figsize=(10, 5))
sns.set_theme(style="whitegrid", font_scale=1.1)

colors = ['#1D2951', '#4B0082', '#6A5ACD', '#9CA3AF']

bottom = None
for idx, column in enumerate(delivery_status_percent.columns):
    plt.bar(
        delivery_status_percent.index,
        delivery_status_percent[column],
        bottom=bottom,
        color=colors[idx],
        label=column,
        edgecolor='white',
        linewidth=0.7
    )
    bottom = (
        delivery_status_percent[column]
        if bottom is None
        else bottom + delivery_status_percent[column]
    )

plt.title('Tỷ lệ trạng thái giao hàng theo phương thức vận chuyển', fontsize=15, weight='bold', pad=15)
plt.xlabel('')
plt.ylabel('Tỷ lệ (%)', fontsize=12)
plt.xticks(fontsize=11)
plt.yticks(fontsize=11)
plt.ylim(0, 105)
plt.grid(axis='y', linestyle='--', alpha=0.4)

plt.legend(
    title='Trạng thái giao hàng',
    loc='center left',
    bbox_to_anchor=(1, 0.5),
    frameon=False,
    fontsize=10,
    title_fontsize=11
)

sns.despine(left=True, right=True, top=True)
plt.tight_layout(rect=[0, 0, 0.85, 1])
plt.show()

"""Delivery Status by Shipping Mode

Biểu đồ thể hiện **tỷ lệ trạng thái giao hàng** (Advance shipping, Late delivery, Shipping canceled, Shipping on time) theo từng **phương thức vận chuyển** (First Class, Same Day, Second Class, Standard Class) của **DataCo Supply Chain**.

---
  Phân tích chính

- **Same Day**: Tỷ lệ giao đúng hạn cao nhất, rất ít đơn bị trễ hoặc hủy — hiệu quả vận hành tối ưu.  
- **First Class**: Chủ yếu giao sớm hoặc đúng hẹn, tỷ lệ trễ thấp.  
- **Second Class**: Tỷ lệ giao đúng hạn vẫn cao nhưng trễ/hủy tăng.  
- **Standard Class**: Giao trễ và hủy nhiều nhất, tỷ lệ đúng hạn thấp nhất.

---

  Kết luận

Phương thức vận chuyển càng **cao cấp (nhanh)** thì khả năng **giao đúng hạn hoặc sớm** càng lớn.  
Ngược lại, các hình thức **thường (Standard Class)** tiềm ẩn **rủi ro trễ/hủy cao hơn**.  
Doanh nghiệp có thể dựa trên biểu đồ này để **điều chỉnh chiến lược logistics** và **nâng cao trải nghiệm khách hàng**.

**SHIPPING DAYS VS. SHIPPING MODE**
"""

import matplotlib.pyplot as plt
import seaborn as sns

shipping_days = data.groupby('Shipping Mode').agg({
    'Days for shipping (real)': 'mean',
    'Days for shipment (scheduled)': 'mean'
}).reset_index()

shipping_days['Delivery Date Variance'] = (
    shipping_days['Days for shipping (real)'] - shipping_days['Days for shipment (scheduled)']
)

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(shipping_days['Shipping Mode'], shipping_days['Days for shipping (real)'],
         label='Thực tế', color='#001F3F', linewidth=2.5, marker='o')
plt.plot(shipping_days['Shipping Mode'], shipping_days['Days for shipment (scheduled)'],
         label='Dự kiến', color='#7B68EE', linewidth=2.5, marker='o')
plt.title('Số ngày giao trung bình theo hình thức vận chuyển', fontsize=11, weight='bold')
plt.xlabel('Hình thức giao hàng', fontsize=10)
plt.ylabel('Số ngày giao trung bình', fontsize=10)
plt.legend(frameon=False)
plt.box(False)

plt.subplot(1, 2, 2)
plt.plot(shipping_days['Shipping Mode'], shipping_days['Delivery Date Variance'],
         color='#4B0082', linewidth=2.5, marker='o')
plt.fill_between(shipping_days['Shipping Mode'], shipping_days['Delivery Date Variance'],
                 color='#9CA3AF', alpha=0.35)
plt.title('Độ chênh lệch ngày giao hàng (thực tế - dự kiến)', fontsize=11, weight='bold')
plt.xlabel('Hình thức giao hàng', fontsize=10)
plt.ylabel('Độ chênh lệch (ngày)', fontsize=10)
plt.box(False)

plt.tight_layout(pad=3)
plt.show()

"""**1. Số ngày giao trung bình**
- **Same Day:** Giao đúng cam kết (~0,5 ngày), hiệu quả cao.  
- **First Class:** Chênh nhẹ (~1 ngày), vẫn trong mức tốt.  
- **Second Class:** Trễ đáng kể (4 ngày thực tế vs 2 ngày dự kiến).  
- **Standard Class:** Thực tế sát dự kiến (4 ngày).

**2. Độ chênh lệch giao hàng**
- **Second Class:** Cao nhất (~2 ngày) → thường xuyên trễ.  
- **First Class & Same Day:** Ổn định, gần khớp dự kiến.  
- **Standard Class:** Gần bằng 0 → đáng tin cậy nhất.

---
 Insight thực tiễn
- **Second Class** là nguyên nhân chính gây trễ, cần xem xét tối ưu quy trình hoặc điều chỉnh cam kết giao hàng.  
- **Same Day** và **Standard Class** hoạt động ổn định, phù hợp làm nhóm dịch vụ trọng tâm.  
- Doanh nghiệp nên **đầu tư mở rộng Same Day** và **kiểm soát rủi ro Second Class** để nâng cao trải nghiệm khách hàng.

##**1.2 Correlation Analysis**
"""

numerical_data = data.select_dtypes(include = ['number']).copy()
numerical_data.head(2)

"""Thời gian thực tế vận chuyển (Days for shipping (real)) là yếu tố quan trọng nhất ảnh hưởng đến rủi ro giao trễ.
→ Có thể dùng làm biến dự báo (predictor) trong mô hình ML.

Thời gian dự kiến (Days for shipment (scheduled)) có quan hệ ngược lại — khi doanh nghiệp lên kế hoạch giao lâu hơn, khả năng giao trễ giảm.

Các yếu tố như giá sản phẩm, mã đơn, khu vực địa lý (Latitude/Longitude) hầu như không ảnh hưởng đến rủi ro giao trễ.
"""

columns_to_drop = [
    'Customer Id', 'Customer Zipcode', 'Order Customer Id', 'Order Id',
    'Order Item Cardprod Id', 'Order Item Id', 'Product Card Id',
    'Product Category Id', 'Category Id', 'Department Id',
    'Latitude', 'Longitude', 'Order Zipcode',
    'Order Item Product Price', 'Order Item Profit Ratio', 'Order Item Quantity',
    'Order Item Discount', 'Product Description', 'Product Status'
]

# Drop cột
numerical_df_cleaned = numerical_data.drop(columns=[c for c in columns_to_drop if c in numerical_data.columns])

corr_pearson = numerical_df_cleaned.corr()

plt.figure(figsize=(12, 10))

mask = np.triu(np.ones_like(corr_pearson, dtype=bool))

colors = sns.color_palette("dark:salmon_r", as_cmap=True)

sns.heatmap(
    corr_pearson,
    annot=True,
    fmt=".2f",
    cmap=colors,
    mask=mask,
    square=True,
    linewidths=1,
    cbar_kws={"shrink": 0.75},
    annot_kws={"size": 12}
)

plt.title('Correlation Heatmap (Selected Numerical Features)', fontsize=18, pad=20)
plt.tight_layout()
plt.show()

"""Ý Nghĩa Các Mối Liên Hệ Chính

- **Days for shipping (real) & Days for shipment (scheduled):** Tương quan mạnh (0.52) → lịch giao dự kiến ảnh hưởng nhiều đến thời gian giao thực tế.  
- **Benefit per order & Order Profit Per Order:** Tương quan gần như tuyệt đối (1.00) → hai biến có thể trùng nội dung.  
- **Sales / Order Item Total / Sales per customer:** Tương quan mạnh (0.99 - 1.00) → dễ hiểu, Sales là tổng Order Item Total.  
- **Product Price:** Tương quan mạnh với Order Item Total & Sales (0.78 - 0.79).  
- **Order Item Discount Rate:** Ngược chiều nhẹ với Sales per customer → giảm giá nhiều, doanh số mỗi khách giảm.  
- **Late_delivery_risk:**  
  - Thuận với Days for shipping (real) (0.40) → giao càng lâu, nguy cơ trễ càng cao.  
  - Ngược với Days for shipment (scheduled) (-0.37) → lịch dự kiến dài, nguy cơ trễ giảm.

 Ý Nghĩa Ứng Dụng ML

- Các biến tương quan cao (~1.0) nên cân nhắc loại bớt để tránh đa cộng tuyến.  
- Late_delivery_risk cần chú ý các yếu tố về thời gian giao, discount rate.  
- Biến độc lập hoặc yếu liên hệ có thể bổ trợ, tăng độ đa dạng/hiệu quả mô hình.

 Kết Luận

Heatmap giúp nhận diện nhóm biến đồng biến/mâu thuẫn, gợi ý chọn biến và giải thích các luồng tác động trong supply chain, đồng thời là công cụ loại bỏ thông tin trùng lặp khi xây dựng mô hình AI/ML.

#**2. Data cleaning**

##**2.1 Missing values**
"""

data.info()

data.isnull().sum()

data.describe()

columns_to_drop = ['Order Zipcode', 'Product Description', 'Customer Id', 'Order Id', 'Product Card Id',
                   'Latitude', 'Longitude', 'Customer Email', 'Customer Fname',
                   'Customer Lname', 'Customer Password', 'Customer Street',
                   'Order Item Cardprod Id', 'Order Customer Id',
                   'Product Image', 'Product Name', 'Category Name', 'Customer State',
                   'Customer Zipcode', 'Department Name']

data_cleaned = data.drop(columns=columns_to_drop)

"""##**2.2 Outlier**"""

numerical_data = data_cleaned.select_dtypes(include = ['number']).copy()
numerical_data.head(2)

numerical_data.describe()

""" Các Feature Sử Dụng Cho Phân Tích Outliers

- **Benefit per Order**: Giá trị lợi nhuận trên mỗi đơn hàng quá cao hoặc quá thấp có thể cho thấy sự bất thường trong chi phí vận chuyển hoặc xử lý, từ đó dẫn đến việc trễ giao. Ví dụ, lợi nhuận thấp có thể do chi phí logistics quá cao, gây trì hoãn do hiệu quả tài chính kém.

- **Order Item Discount Rate**: Tỷ lệ giảm giá cao có thể thu hút lượng đơn hàng lớn, gây áp lực lên hệ thống hoàn tất đơn hàng và dẫn đến trễ. Nếu mức giảm giá quá cao, điều này có thể phản ánh các chương trình khuyến mãi đặc biệt làm tăng nhu cầu, khiến chuỗi cung ứng quá tải và gây trễ giao hàng.

- **Order Profit Per Order**: Tương tự như lợi nhuận trên đơn hàng, các đơn hàng có lợi nhuận thấp hoặc âm có thể được xử lý ưu tiên thấp hơn, dẫn đến trễ. Ngược lại, các đơn hàng có lợi nhuận cao có thể được ưu tiên xử lý, giảm nguy cơ trễ.

- **Product Price**: Các sản phẩm có giá cao có thể yêu cầu xử lý hoặc vận chuyển đặc biệt, làm tăng độ phức tạp của việc giao hàng và tăng nguy cơ trễ.

- **Sales per Customer**: Các giá trị ngoại lệ về doanh số trên mỗi khách hàng có thể cho thấy khách mua với khối lượng lớn hoặc số lượng đơn hàng nhiều, dẫn đến thời gian xử lý dài hơn và tăng rủi ro trễ giao.

"""

features = [
    "Benefit per order",
    "Order Item Discount Rate",
    "Order Profit Per Order",
    "Product Price",
    "Sales per customer",
    "Days for shipping (real)",
    "Days for shipment (scheduled)"
]

color = '#000080'  # xanh navy

fig, axes = plt.subplots(3, 3, figsize=(12, 8))
axes = axes.flatten()

for i, feature in enumerate(features):
    axes[i].hist(data_cleaned[feature], bins=20, color=color, edgecolor="black")
    axes[i].set_title(feature, fontsize=10)
    axes[i].tick_params(axis='x', labelsize=8)
    axes[i].tick_params(axis='y', labelsize=8)
    axes[i].grid(False)  # tắt grid line

# Xóa subplot thừa nếu có
for j in range(i+1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

""" Phân tích Outliers

Do **"Days for shipping (real)"** và **"Days for shipment (scheduled)"** có phân phối gần chuẩn và có mối tương quan cao với biến mục tiêu **"Late delivery risk"**, việc giữ lại outliers trong các biến này có thể **bảo toàn sức mạnh dự báo**. Các outliers trong những biến có tương quan mạnh với target có thể đại diện cho những biến thể quan trọng góp phần vào rủi ro giao hàng trễ, đặc biệt khi xét đến thời gian giao hàng.

Dựa trên histogram ở trên, **Order Item Discount Rate** có phân phối tương đối chuẩn, với các cột rời rạc phản ánh các mức chiết khấu cố định (ví dụ: 5%, 10%, v.v.). Giá trị phân bổ đều trong khoảng mong đợi và không có outliers bất thường đáng lo ngại.

Ngược lại, với các biến có **tương quan thấp với target** (như thông tin khách hàng), outliers có thể **không quan trọng**, và việc làm sạch chúng (loại bỏ hoặc thay thế) **không ảnh hưởng đáng kể đến độ chính xác dự báo**.

- **Z-score** cho "Benefit per Order" và "Order Profit per Order":  
  Hai biến này có dữ liệu gần phân phối chuẩn. Z-score phù hợp để nhận diện outliers trong phân phối chuẩn vì đo lường mức độ lệch của điểm dữ liệu so với trung bình theo số độ lệch chuẩn.

- **IQR** cho "Product Price" và "Sales per Customer":  
  Những biến này có phân phối lệch phải. IQR hiệu quả hơn khi xử lý các phân phối lệch, vì nó xét đến khoảng trải rộng của 50% dữ liệu giữa và đánh dấu các giá trị nằm ngoài khoảng này là outliers.

"""

from scipy import stats

def z_score_outliers(data):
    threshold = 3
    mean = np.mean(data)
    std = np.std(data)
    z_scores = (data - mean) / std
    return np.abs(z_scores) > threshold

def iqr_outliers(data):
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return (data < lower_bound) | (data > upper_bound)

z_score_outliers_benefit = z_score_outliers(data_cleaned["Benefit per order"])
z_score_outliers_profit = z_score_outliers(data_cleaned["Order Profit Per Order"])


iqr_outliers_product_price = iqr_outliers(data_cleaned["Product Price"])
iqr_outliers_sales_customer = iqr_outliers(data_cleaned["Sales per customer"])



print(f"Number of outliers in Benefit per Order (Z-score): {z_score_outliers_benefit.sum()}")
print(f"Number of outliers in Order Profit Per Order (Z-score): {z_score_outliers_profit.sum()}")
print(f"Number of outliers in Product Price (IQR): {iqr_outliers_product_price.sum()}")
print(f"Number of outliers in Sales per Customer (IQR): {iqr_outliers_sales_customer.sum()}")

""" Xử lý Outliers

 1. Lý do thay thế outliers bằng Median
Median (giá trị trung vị) là một chỉ số trung tâm **không bị ảnh hưởng nhiều bởi các giá trị cực đoan**. Khi dữ liệu có outliers hoặc bị lệch, việc sử dụng median phản ánh xu hướng trung tâm thực sự tốt hơn mean (trung bình).

 2. Ảnh hưởng của độ lệch (Skewness)

 Dữ liệu lệch phải (Right-skewed)
- Ví dụ: `Product Price`, `Sales per Customer`
- Đặc điểm: Đuôi dài bên phải (có vài giá trị rất cao kéo mean lên)
- Giải pháp: Thay outliers bằng median để phản ánh giá trị điển hình mà không bị các giá trị cực lớn làm sai lệch.

 Dữ liệu lệch trái (Left-skewed)
- Ví dụ: `Benefit per Order`, `Order Profit Per Order`
- Đặc điểm: Đuôi dài bên trái (các giá trị âm cực đoan)
- Giải pháp: Thay outliers bằng median để các giá trị cực nhỏ/âm không ảnh hưởng quá nhiều, duy trì sự cân bằng cho phân tích.

 3. Kết luận
Việc sử dụng median giúp dữ liệu **ổn định, cân bằng**, đặc biệt với dữ liệu có giá trị cực đoan hoặc phân phối lệch.

"""

median_benefit = data_cleaned["Benefit per order"].median()
data_cleaned.loc[z_score_outliers_benefit, "Benefit per order"] = median_benefit

median_profit = data_cleaned["Order Profit Per Order"].median()
data_cleaned.loc[z_score_outliers_profit, "Order Profit Per Order"] = median_profit

median_product_price = data_cleaned["Product Price"].median()
data_cleaned.loc[iqr_outliers_product_price, "Product Price"] = median_product_price

median_sales_customer = data_cleaned["Sales per customer"].median()
data_cleaned.loc[iqr_outliers_sales_customer, "Sales per customer"] = median_sales_customer

features = ["Benefit per order", "Order Profit Per Order", "Product Price", "Sales per customer"]
color = '#6A5ACD'
fig, axes = plt.subplots(2, 2, figsize=(12, 8))
axes = axes.flatten()

for i, feature in enumerate(features):
    axes[i].hist(data_cleaned[feature], bins=20, color=color, edgecolor="black")
    axes[i].set_title(feature, fontsize=12)
    axes[i].tick_params(axis='x', labelsize=10)
    axes[i].tick_params(axis='y', labelsize=10)
    axes[i].grid(False)

plt.tight_layout()
plt.show()

data_cleaned.head()

data_cleaned.info()

data_cleaned.to_csv("/content/drive/MyDrive/DATN/data_for_visualization.csv", index=False)

"""# **3. Feature selection**

##**3.1 Categorical Features Selection**
"""

categorical_data = data_cleaned.select_dtypes(include = ['object']).copy()
categorical_data["y"] = data_cleaned["Late_delivery_risk"]
categorical_data.head(5)

X_cat = categorical_data.drop(columns = ["y"])
y_cat = categorical_data["y"]

from scipy.stats import chi2_contingency

for col in X_cat.columns:
    table = pd.crosstab(X_cat[col], y_cat)
    print ('\n', table)
    _, pval, _, expected_table = chi2_contingency(table)
    print('Feature:', col, '| p-value:', pval)

data_cleaned["Order City"].nunique()

columns_to_remove = ['Customer Country', 'Customer Segment', 'Market', 'Delivery Status',
                     'Customer City', 'Order City', 'Order Region', 'Order State', 'Order Status']


data_cleaned = data_cleaned.drop(columns=columns_to_remove)

"""Loại bỏ các feature categorical không cần thiết

- **Customer Country, Customer Segment, Market**: p-value cao → không có ý nghĩa thống kê, ít đóng góp cho dự đoán `Late_delivery_risk`.  
- **Delivery Status**: trực tiếp liên quan đến target → trùng lặp, loại bỏ.  
- **Customer City, Order City**: quá nhiều giá trị duy nhất (3000+) → tăng độ phức tạp, ít giá trị dự đoán.  
- **Order Region**: tương tự Customer Country, p-value cao → loại bỏ.  
- **Order State**: giống Order City → quá nhiều giá trị duy nhất → loại bỏ.  
- **Order Status**: không cần, chỉ quan tâm đơn hoàn thành, đã thanh toán → loại bỏ.  

**Mục tiêu:** làm sạch dữ liệu, giảm biến dư thừa, tập trung vào các feature quan trọng cho mô hình.

## **3.2 Numerical Features Selection**
"""

numeric_mask1 = data_cleaned.select_dtypes(include='number').columns
numeric_features1 = data_cleaned[numeric_mask1]

from sklearn.feature_selection import VarianceThreshold

var_th = VarianceThreshold(threshold=0.05)
var_th.fit_transform(numeric_features1)

numeric_features1.head()

var_th.get_support()

X_num = numeric_features1.drop(columns = ["Late_delivery_risk"])
y_num = numeric_features1["Late_delivery_risk"]

import scipy

print(f"{'col':<30} {'corr':<10} {'pval':<10}")
for col in X_num.columns:
    corr = np.nan
    pval = np.nan
    if X_num[col].nunique() > 1:  # Check if column has more than one unique value
        corr, pval = scipy.stats.pearsonr(X_num[col], y_num)

    print(f"{col:<30} {corr:>10.2f} {pval:>10.4f}")

from sklearn.feature_selection import mutual_info_regression
list(zip(X_num.columns, mutual_info_regression(X_num, y_num, random_state=123, n_neighbors=3)))

""" Quyết định loại bỏ đặc trưng

Dựa trên phân tích:

- **Order Item Discount Rate**: Được xác định bởi phương pháp ngưỡng phương sai là có phương sai rất thấp, nghĩa là không cung cấp thông tin hữu ích để phân biệt các bản ghi. Giữ lại đặc trưng này sẽ không cải thiện hiệu suất mô hình.  

- **Product Status**: Có tương quan NaN với biến mục tiêu và điểm thông tin hỗ trợ (mutual information) bằng 0, cho thấy không liên quan đến dự đoán rủi ro giao hàng trễ.  

**Kết luận:** Cả hai đặc trưng này được loại bỏ để giảm nhiễu và độ phức tạp không cần thiết cho mô hình dự đoán.

"""

features_to_remove = ['Order Item Discount Rate', 'Product Status']

data_cleaned = data_cleaned.drop(columns=features_to_remove)

data_cleaned.dtypes

data_cleaned["Order Item Profit Ratio"].nunique()

data_cleaned["Order Item Id"].unique()

data_cleaned = data_cleaned.drop(columns = "Order Item Id")

data_cleaned.dtypes

"""#**4. New Features Creation**"""

# Convert the columns to datetime format
data_cleaned['shipping date (DateOrders)'] = pd.to_datetime(data_cleaned['shipping date (DateOrders)'])
data_cleaned['order date (DateOrders)'] = pd.to_datetime(data_cleaned['order date (DateOrders)'])

data_cleaned['Order_to_Shipment_Time'] = ((data_cleaned['shipping date (DateOrders)'] - data_cleaned['order date (DateOrders)']).astype('timedelta64[s]') / pd.Timedelta(hours=1)).astype(int)
data_cleaned['Order_to_Shipment_Time'].values

data_cleaned['ship_day_of_week'] = data_cleaned['shipping date (DateOrders)'].dt.dayofweek
data_cleaned.head()

data_cleaned['order_day_of_week'] = data_cleaned['order date (DateOrders)'].dt.dayofweek
data_cleaned.head()

data_cleaned['ship_day_of_week_name'] = data_cleaned['ship_day_of_week'].map({
    0: 'Monday',
    1: 'Tuesday',
    2: 'Wednesday',
    3: 'Thursday',
    4: 'Friday',
    5: 'Saturday',
    6: 'Sunday'
})
data_cleaned['order_day_of_week_name'] = data_cleaned['order_day_of_week'].map({
    0: 'Monday',
    1: 'Tuesday',
    2: 'Wednesday',
    3: 'Thursday',
    4: 'Friday',
    5: 'Saturday',
    6: 'Sunday'
})

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

colors = ['#000080', '#1D2951', '#4B0082', '#6A5ACD', '#7B68EE',
          '#9CA3AF', '#5F6F94', '#8791B2', '#A0A5C8', '#C5CAE9']

plt.figure(figsize=(10, 6))
ax = sns.countplot(
    x='order_day_of_week_name',
    data=data_cleaned,
    palette=colors[:7]
)

for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width()/2,
            height + 500,
            f'{int(height)}',
            ha='center',
            va='bottom',
            fontsize=10)

plt.title('Số lượng đơn theo ngày trong tuần', fontsize=16)
plt.xlabel('Ngày trong tuần')
plt.ylabel('Số lượng đơn')
plt.show()

data_cleaned['ship_hour'] = data_cleaned['shipping date (DateOrders)'].dt.hour
data_cleaned.head()

data_cleaned['order_hour'] = data_cleaned['order date (DateOrders)'].dt.hour
data_cleaned.head()

def f(x):
    if (x > 4) and (x <= 8):
        return 'Early Morning'
    elif (x > 8) and (x <= 12 ):
        return 'Morning'
    elif (x > 12) and (x <= 16):
        return'Noon'
    elif (x > 16) and (x <= 20) :
        return 'Eve'
    elif (x > 20) and (x <= 24):
        return'Night'
    elif (x <= 4):
        return'Late Night'

data_cleaned['order date (DateOrders)'] = pd.to_datetime(data_cleaned['order date (DateOrders)'])
data_cleaned['shipping date (DateOrders)'] = pd.to_datetime(data_cleaned['shipping date (DateOrders)'])

data_cleaned['ship_hour'] = data_cleaned['shipping date (DateOrders)'].dt.hour
data_cleaned['order_hour'] = data_cleaned['order date (DateOrders)'].dt.hour

data_cleaned['ship_daypart'] = data_cleaned['ship_hour'].apply(f)
data_cleaned['order_daypart'] = data_cleaned['order_hour'].apply(f)

data_cleaned['ship_daypart_n'] = data_cleaned['ship_daypart'].map({
    'Early Morning': 0,
    'Morning': 1,
    'Noon': 2,
    'Eve': 3,
    'Night': 4,
    'Late Night': 5
})
data_cleaned['order_daypart_n'] = data_cleaned['order_daypart'].map({
    'Early Morning': 0,
    'Morning': 1,
    'Noon': 2,
    'Eve': 3,
    'Night': 4,
    'Late Night': 5
})
data_cleaned.head()

data_cleaned.dtypes

# Drop Useless Categorical
data_cleaned.drop(['order date (DateOrders)', 'shipping date (DateOrders)', 'ship_day_of_week_name',
           'order_day_of_week_name', 'ship_daypart', 'order_daypart', 'Order Country'], axis=1, inplace=True)

data_cleaned = pd.read_csv('/content/drive/MyDrive/DATN/data_clean_ver1.csv')



"""#**5. Data preprocessing**"""

data_cleaned.info()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder
from category_encoders import OneHotEncoder as OHE

columns_to_drop = [
    'Days for shipping (real)',
    'Order_to_Shipment_Time',
    'ship_day_of_week',
    'ship_hour',
    'ship_daypart_n'
]

data_cleaned = data_cleaned.drop(columns=columns_to_drop)

seed = 42
train_set, test_set = train_test_split(data_cleaned, test_size=0.2, random_state=seed, stratify=data_cleaned['Late_delivery_risk'])

X_train = train_set.drop(['Late_delivery_risk'], axis=1)
y_train = train_set['Late_delivery_risk']

X_test = test_set.drop(['Late_delivery_risk'], axis=1)
y_test = test_set['Late_delivery_risk']

"""##**5.1 Categorical Features Encoding**"""

from sklearn.model_selection import train_test_split
seed = 42

train_set, test_set = train_test_split(data_cleaned, test_size = 0.2, random_state = seed)

X_train = train_set.drop(['Late_delivery_risk'], axis = 'columns')
y_train = train_set['Late_delivery_risk']

X_test = test_set.drop(['Late_delivery_risk'], axis = 1)
y_test = test_set['Late_delivery_risk']

data_cleaned.select_dtypes(include='object').columns

data_cleaned["Shipping Mode"].unique()

from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, OneHotEncoder

ord_enc_shipping_mode = OrdinalEncoder(categories=[["Standard Class", "Second Class", "First Class", "Same Day"]])

X_train["Shipping Mode"] = ord_enc_shipping_mode.fit_transform(X_train[["Shipping Mode"]])
X_test["Shipping Mode"] = ord_enc_shipping_mode.transform(X_test[["Shipping Mode"]])

X_train["Shipping Mode"].head(4)

!pip install category_encoders

from category_encoders import OneHotEncoder as OHE

ohe = OHE(cols=['Type'], use_cat_names=True)


X_train = ohe.fit_transform(X_train)
X_test = ohe.transform(X_test)

X_train.head()

X_train.dtypes

"""##**5.2 Numerical features**"""

ord_enc_shipping_mode = OrdinalEncoder(
    categories=[["Standard Class", "Second Class", "First Class", "Same Day"]]
)

X_train["Shipping Mode"] = ord_enc_shipping_mode.fit_transform(X_train[["Shipping Mode"]])
X_test["Shipping Mode"] = ord_enc_shipping_mode.transform(X_test[["Shipping Mode"]])

ohe = OHE(cols=['Type'], use_cat_names=True)
X_train = ohe.fit_transform(X_train)
X_test = ohe.transform(X_test)

X_train.info()

X_train.head()

scaler = MinMaxScaler()

numerical_features_to_scale = [
    "Days for shipment (scheduled)",
    "Benefit per order",
    "Sales per customer",
    "Order Item Discount",
    "Order Item Product Price",
    "Order Item Profit Ratio",
    "Order Item Quantity",
    "Sales",
    "Order Item Total",
    "Order Profit Per Order",
    "Product Price"
]

X_train[numerical_features_to_scale] = scaler.fit_transform(X_train[numerical_features_to_scale])
X_test[numerical_features_to_scale] = scaler.transform(X_test[numerical_features_to_scale])

"""#**6. Machine learning algorithm**

Lựa chọn thuật toán

**Random Forest**:

* Thích hợp cho chọn đặc trưng (feature selection).
* Xử lý tốt cả dữ liệu số và phân loại.
* Chịu được ngoại lệ (outliers).
* Thích hợp với tập dữ liệu lớn, cung cấp thông tin về độ quan trọng của các đặc trưng.
* Giảm overfitting nhờ phương pháp ensemble.

**Logistic Regression**:

* Thuật toán cơ bản, dễ giải thích.
* Tốt cho phân loại nhị phân, cho biết tầm quan trọng của đặc trưng thông qua hệ số (coefficients).
* Phù hợp với dữ liệu cân bằng.


**XGBoost**:

* Thuật toán hiệu suất cao, thường đạt kết quả tốt trong các cuộc thi.
* Xử lý tốt dữ liệu lớn, cung cấp thông tin về độ quan trọng của đặc trưng.
* Có cơ chế regularization giảm overfitting, xử lý tốt dữ liệu thiếu và dữ liệu lệch lớp.


**TabPFN**

##**6.1 Logistic regresstion**
"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

lr_model = LogisticRegression(max_iter=1000, random_state=seed, class_weight='balanced')
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)

print(f"\nAccuracy: {accuracy_score(y_test, y_pred_lr):.6f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_lr))

cm_lr = confusion_matrix(y_test, y_pred_lr)
print(f"\nConfusion Matrix:")
print(cm_lr)
print(f"[[TN={cm_lr[0,0]:,}  FP={cm_lr[0,1]:,}]")
print(f" [FN={cm_lr[1,0]:,}  TP={cm_lr[1,1]:,}]]")

plt.figure(figsize=(6, 5))
sns.heatmap(
    cm_lr,
    annot=True,
    fmt='g',
    cmap='Blues',
    cbar=False,
    linewidths=0,
    square=True,
    xticklabels=['Không trễ', 'Trễ'],
    yticklabels=['Không trễ', 'Trễ'],
    annot_kws={"size": 12, "weight": "bold"}
)
plt.xlabel('Dự đoán', fontsize=13, fontweight='bold')
plt.ylabel('Thực tế', fontsize=13, fontweight='bold')
plt.title('Confusion Matrix - Logistic Regression', fontsize=14, fontweight='bold', pad=15)
for spine in plt.gca().spines.values():
    spine.set_visible(False)
plt.tight_layout()
plt.show()

coefficients = pd.DataFrame({
    'Feature': X_train.columns,
    'Coefficient': lr_model.coef_[0],
    'Abs_Coefficient': np.abs(lr_model.coef_[0])
}).sort_values('Abs_Coefficient', ascending=False)

print("\nTop 10 Most Important Features:")
print(coefficients.head(10).to_string(index=False))

"""## **6.2 TabPFN**"""

!huggingface-cli login

!pip install --upgrade tabpfn

print("="*60)
print("TABPFN (10,000 samples)")
print("="*60)

# Chuẩn bị 10k samples cho TabPFN
X_train_10k = X_train.sample(n=10000, random_state=seed)
y_train_10k = y_train.loc[X_train_10k.index]

print(f"Training on {X_train_10k.shape[0]} samples with {X_train_10k.shape[1]} features")

# Import TabPFN
from tabpfn import TabPFNClassifier

# Train model - BỎ N_ensemble_configurations
clf_tabpfn = TabPFNClassifier(device='cuda')
clf_tabpfn.fit(X_train_10k.values, y_train_10k.values)

# Predict
y_pred_tabpfn = clf_tabpfn.predict(X_test.values)

print(f"\nAccuracy: {accuracy_score(y_test, y_pred_tabpfn):.6f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_tabpfn))

# Confusion Matrix
cm_tabpfn = confusion_matrix(y_test, y_pred_tabpfn)
print(f"\nConfusion Matrix:")
print(cm_tabpfn)

# Visualize
plt.figure(figsize=(6, 5))
sns.heatmap(
    cm_tabpfn,
    annot=True,
    fmt='g',
    cmap='Blues',
    cbar=False,
    linewidths=0,
    square=True,
    xticklabels=['Không trễ', 'Trễ'],
    yticklabels=['Không trễ', 'Trễ'],
    annot_kws={"size": 12, "weight": "bold"}
)

plt.xlabel('Dự đoán', fontsize=13, fontweight='bold')
plt.ylabel('Thực tế', fontsize=13, fontweight='bold')
plt.title('Confusion Matrix - TabPFN', fontsize=14, fontweight='bold', pad=15)

for spine in plt.gca().spines.values():
    spine.set_visible(False)

plt.tight_layout()
plt.show()

print("\nTabPFN training completed")
print(f"Trained on {X_train_10k.shape[0]} samples (algorithm limitation)")

"""## **6.3 Xg Boost**"""

!pip install xgboost

# XGBOOST

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("="*60)
print("XGBOOST")
print("="*60)

xgb_model = XGBClassifier(random_state=seed, eval_metric='logloss')
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)

print(f"\nAccuracy: {accuracy_score(y_test, y_pred_xgb):.6f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_xgb))

# Confusion Matrix
cm_xgb = confusion_matrix(y_test, y_pred_xgb)
print(f"\nConfusion Matrix:")
print(cm_xgb)

# Visualize
plt.figure(figsize=(6, 5))
sns.heatmap(
    cm_xgb,
    annot=True,
    fmt='g',
    cmap='Blues',
    cbar=False,
    linewidths=0,
    square=True,
    xticklabels=['Không trễ', 'Trễ'],
    yticklabels=['Không trễ', 'Trễ'],
    annot_kws={"size": 12, "weight": "bold"}
)

plt.xlabel('Dự đoán', fontsize=13, fontweight='bold')
plt.ylabel('Thực tế', fontsize=13, fontweight='bold')
plt.title('Confusion Matrix - XGBoost', fontsize=14, fontweight='bold', pad=15)

for spine in plt.gca().spines.values():
    spine.set_visible(False)

plt.tight_layout()
plt.show()

# Feature Importances
xgb_feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': xgb_model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nTop 10 Important Features:")
print(xgb_feature_importances.head(10))

"""# **CONCLUSION**"""

data_cleaned.head()

